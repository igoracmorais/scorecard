{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import scorecardpy as sc\n",
    "import time\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns',None)\n",
    "diretorio=os.getcwd()\n",
    "diretorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vez que já temos o melhor modelo estimado com seus hyperparametros, voltamos ao pacote scorecardpy para aplicar esse resultado nos dados e construir os scores para cada individuo. Isso encerra esse ciclo de estudo para scorecard. Os melhoramentos que podem ser feitos aqui são de 3 tipos: i) novos dados; ii) tratamento dos dados; iii) diferentes estimadores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo\n",
    "Uma vez estimado o modelo final, podemos usar o mesmo no banco de dados para determinar os valores do score  para cliente.  Mas antes, vamos abrir o modelo que foi salvo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"modelo_LR.pkl\", 'rb') as file:  \n",
    "    modelo = pickle.load(file)\n",
    "\n",
    "modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados\n",
    "Os dados que usamos para fazer a parte final são os mesmos que usamos para fazer a investigação do woe e IV no notebook3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Job</th>\n",
       "      <th>Housing</th>\n",
       "      <th>Saving accounts</th>\n",
       "      <th>Checking account</th>\n",
       "      <th>Credit amount</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>own</td>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>1169</td>\n",
       "      <td>6</td>\n",
       "      <td>radio/TV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>own</td>\n",
       "      <td>little</td>\n",
       "      <td>moderate</td>\n",
       "      <td>5951</td>\n",
       "      <td>48</td>\n",
       "      <td>radio/TV</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age     Sex  Job Housing Saving accounts Checking account  Credit amount  \\\n",
       "0   67    male    2     own          little           little           1169   \n",
       "1   22  female    2     own          little         moderate           5951   \n",
       "\n",
       "   Duration   Purpose  default  \n",
       "0         6  radio/TV        1  \n",
       "1        48  radio/TV        0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('german_credit_data2.csv',index_col=0)\n",
    "dataset['default']=np.where(dataset['default']=='yes',1,0)\n",
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos a quantidade total de dados pois não há necessidade de separar entre treino e teste como na estimativa feita no notebook5 na escolha do melhor modelo. Agora nos ja temos o melhor modelo, e aplicamos seus coeficientes na estimativa do score para todos os dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. scorecard\n",
    "Para usar o modelo na construção dos scores, aplicamos duas funções: i) scorecard; ii) scorecard_ply. <br>\n",
    "A função scorecard recebe como parametros importantes:\n",
    "1. bins: o arquivo derivado do woebin;\n",
    "2. model: especificação do modelo usado com os parâmetros estimados;\n",
    "3. xcolumns: nome das colunas do banco de dados;\n",
    "4. points0: ponto máximo para o score. Default=600. Caso queira um score que possa ir de 0-1000 mude o valor para 1000.\n",
    "5. odds0: meta da chance p/(1-p)\n",
    "6. pdo: valor para dobrar a chance. Default = 50;\n",
    "7. basepoints_eq0: Default = False. Se for True, distribui o ponto base de forma igual para todas as variaveis;\n",
    "8. digits: numero de digitos apos a casa decimal. Default=0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Os bins\n",
    "Anteriormente aplicamos a função woebin para encontrar qual seria o melhor intervalo para cada variável utilizada. Podemos salvar esse arquivo e depois importar esse dicionário aqui. Abaixo temos esses valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load woebin_20210616_230040.py\n",
    "breaks_list={\n",
    "'Age': [23.0,30.0,32.0,40.0,44.0,48.0,54.0], \n",
    "'Checking account': ['rich','moderate','little'], \n",
    "'Credit amount': [800.0,2400.0,3800.0,4800.0,6800.0,8800.0], \n",
    "'Duration': [10.0,14.0,18.0,22.0,30.0,44.0], \n",
    "'Housing': ['free','own','rent'], \n",
    "'Job': [2.0,3.0], \n",
    "'Purpose': ['domestic appliances%,%vacation/others%,%repairs%,%car','radio/TV','furniture/equipment','business%,%education'], \n",
    "'Saving accounts': ['little','quite rich','rich%,%moderate'], \n",
    "'Sex': ['female','male']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou então replicar a função nos ddados para ter esse valor...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating woe binning ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Credit amount':         variable              bin  count  count_distr  good  bad   badprob  \\\n",
       " 0  Credit amount     [-inf,800.0)     74        0.074    49   25  0.337838   \n",
       " 1  Credit amount   [800.0,2400.0)    449        0.449   323  126  0.280624   \n",
       " 2  Credit amount  [2400.0,3800.0)    203        0.203   133   70  0.344828   \n",
       " 3  Credit amount  [3800.0,4800.0)     80        0.080    59   21  0.262500   \n",
       " 4  Credit amount  [4800.0,6800.0)     81        0.081    66   15  0.185185   \n",
       " 5  Credit amount  [6800.0,8800.0)     57        0.057    36   21  0.368421   \n",
       " 6  Credit amount     [8800.0,inf)     56        0.056    41   15  0.267857   \n",
       " \n",
       "         woe    bin_iv  total_iv  breaks  is_special_values  \n",
       " 0  0.207914  0.003330  0.052153   800.0              False  \n",
       " 1 -0.060512  0.001623  0.052153  2400.0              False  \n",
       " 2  0.239004  0.012139  0.052153  3800.0              False  \n",
       " 3 -0.152157  0.001792  0.052153  4800.0              False  \n",
       " 4 -0.600746  0.025326  0.052153  6800.0              False  \n",
       " 5  0.341862  0.007095  0.052153  8800.0              False  \n",
       " 6 -0.124664  0.000847  0.052153     inf              False  ,\n",
       " 'Sex':   variable     bin  count  count_distr  good  bad   badprob       woe  \\\n",
       " 0      Sex  female    310         0.31   222   88  0.283871 -0.044483   \n",
       " 1      Sex    male    690         0.69   485  205  0.297101  0.019719   \n",
       " \n",
       "      bin_iv  total_iv  breaks  is_special_values  \n",
       " 0  0.000608  0.000877  female              False  \n",
       " 1  0.000269  0.000877    male              False  ,\n",
       " 'Housing':   variable   bin  count  count_distr  good  bad   badprob       woe    bin_iv  \\\n",
       " 0  Housing  free    108        0.108    80   28  0.259259 -0.168964  0.002972   \n",
       " 1  Housing   own    713        0.713   502  211  0.295933  0.014116  0.000142   \n",
       " 2  Housing  rent    179        0.179   125   54  0.301676  0.041528  0.000311   \n",
       " \n",
       "    total_iv breaks  is_special_values  \n",
       " 0  0.003426   free              False  \n",
       " 1  0.003426    own              False  \n",
       " 2  0.003426   rent              False  ,\n",
       " 'Age':   variable          bin  count  count_distr  good  bad   badprob       woe  \\\n",
       " 0      Age  [-inf,23.0)     57        0.057    35   22  0.385965  0.416552   \n",
       " 1      Age  [23.0,30.0)    314        0.314   229   85  0.270701 -0.110213   \n",
       " 2      Age  [30.0,32.0)     78        0.078    49   29  0.371795  0.356334   \n",
       " 3      Age  [32.0,40.0)    252        0.252   177   75  0.297619  0.022196   \n",
       " 4      Age  [40.0,44.0)     81        0.081    64   17  0.209877 -0.444812   \n",
       " 5      Age  [44.0,48.0)     67        0.067    47   20  0.298507  0.026443   \n",
       " 6      Age  [48.0,54.0)     62        0.062    39   23  0.370968  0.352791   \n",
       " 7      Age   [54.0,inf)     89        0.089    67   22  0.247191 -0.232792   \n",
       " \n",
       "      bin_iv  total_iv breaks  is_special_values  \n",
       " 0  0.010656  0.052397   23.0              False  \n",
       " 1  0.003725  0.052397   30.0              False  \n",
       " 2  0.010572  0.052397   32.0              False  \n",
       " 3  0.000125  0.052397   40.0              False  \n",
       " 4  0.014458  0.052397   44.0              False  \n",
       " 5  0.000047  0.052397   48.0              False  \n",
       " 6  0.008233  0.052397   54.0              False  \n",
       " 7  0.004582  0.052397    inf              False  ,\n",
       " 'Job':   variable         bin  count  count_distr  good  bad   badprob       woe  \\\n",
       " 0      Job  [-inf,2.0)    222        0.222   156   66  0.297297  0.020657   \n",
       " 1      Job   [2.0,3.0)    630        0.630   446  184  0.292063 -0.004525   \n",
       " 2      Job   [3.0,inf)    148        0.148   105   43  0.290541 -0.011902   \n",
       " \n",
       "      bin_iv  total_iv breaks  is_special_values  \n",
       " 0  0.000095  0.000129    2.0              False  \n",
       " 1  0.000013  0.000129    3.0              False  \n",
       " 2  0.000021  0.000129    inf              False  ,\n",
       " 'Purpose':   variable                                                bin  count  \\\n",
       " 0  Purpose  domestic appliances%,%vacation/others%,%repair...    383   \n",
       " 1  Purpose                                           radio/TV    280   \n",
       " 2  Purpose                                furniture/equipment    181   \n",
       " 3  Purpose                               business%,%education    156   \n",
       " \n",
       "    count_distr  good  bad   badprob       woe    bin_iv  total_iv  \\\n",
       " 0        0.383   276  107  0.279373 -0.066714  0.001681  0.004946   \n",
       " 1        0.280   199   81  0.289286 -0.017998  0.000090  0.004946   \n",
       " 2        0.181   126   55  0.303867  0.051909  0.000493  0.004946   \n",
       " 3        0.156   106   50  0.320513  0.129442  0.002682  0.004946   \n",
       " \n",
       "                                               breaks  is_special_values  \n",
       " 0  domestic appliances%,%vacation/others%,%repair...              False  \n",
       " 1                                           radio/TV              False  \n",
       " 2                                furniture/equipment              False  \n",
       " 3                               business%,%education              False  ,\n",
       " 'Duration':    variable          bin  count  count_distr  good  bad   badprob       woe  \\\n",
       " 0  Duration  [-inf,10.0)    143        0.143   103   40  0.279720 -0.064991   \n",
       " 1  Duration  [10.0,14.0)    220        0.220   151   69  0.313636  0.097685   \n",
       " 2  Duration  [14.0,18.0)     70        0.070    54   16  0.228571 -0.335537   \n",
       " 3  Duration  [18.0,22.0)    151        0.151   108   43  0.284768 -0.040073   \n",
       " 4  Duration  [22.0,30.0)    203        0.203   137   66  0.325123  0.150532   \n",
       " 5  Duration  [30.0,44.0)    143        0.143   105   38  0.265734 -0.135516   \n",
       " 6  Duration   [44.0,inf)     70        0.070    49   21  0.300000  0.033560   \n",
       " \n",
       "      bin_iv  total_iv breaks  is_special_values  \n",
       " 0  0.000596  0.017651   10.0              False  \n",
       " 1  0.002141  0.017651   14.0              False  \n",
       " 2  0.007305  0.017651   18.0              False  \n",
       " 3  0.000240  0.017651   22.0              False  \n",
       " 4  0.004739  0.017651   30.0              False  \n",
       " 5  0.002551  0.017651   44.0              False  \n",
       " 6  0.000079  0.017651    inf              False  ,\n",
       " 'Checking account':            variable       bin  count  count_distr  good  bad   badprob  \\\n",
       " 0  Checking account      rich     63        0.063    46   17  0.269841   \n",
       " 1  Checking account  moderate    269        0.269   192   77  0.286245   \n",
       " 2  Checking account    little    668        0.668   469  199  0.297904   \n",
       " \n",
       "         woe    bin_iv  total_iv    breaks  is_special_values  \n",
       " 0 -0.114570  0.000807  0.001468      rich              False  \n",
       " 1 -0.032832  0.000288  0.001468  moderate              False  \n",
       " 2  0.023560  0.000373  0.001468    little              False  ,\n",
       " 'Saving accounts':           variable              bin  count  count_distr  good  bad   badprob  \\\n",
       " 0  Saving accounts           little    786        0.786   571  215  0.273537   \n",
       " 1  Saving accounts       quite rich     63        0.063    43   20  0.317460   \n",
       " 2  Saving accounts  rich%,%moderate    151        0.151    93   58  0.384106   \n",
       " \n",
       "         woe    bin_iv  total_iv           breaks  is_special_values  \n",
       " 0 -0.095893  0.007082  0.035082           little              False  \n",
       " 1  0.115390  0.000858  0.035082       quite rich              False  \n",
       " 2  0.408702  0.027142  0.035082  rich%,%moderate              False  }"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "woe_bin=sc.woebin(dt=dataset, y='default',method=\"tree\")\n",
    "woe_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. aplicando na função scorecard\n",
    "De posse dos intervalos e do modelo, usamos a função scorecard para converter isso em um conjunto de informação para uso posterior. Essa é a única utilidade dessa função, unir o estimador com os intervalos, não se esquecendo de fornecer o nome das colunas do banco de dados. Veja que importamos a lista de intervalos que foi salva a partir do notebook3 onde aplicamos o pacote scorecardpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'basepoints':      variable  bin  points\n",
       " 0  basepoints  NaN   788.0}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=dataset.drop(['default'],axis=1)\n",
    "card=sc.scorecard(bins='woebin_20210616_230040.py', \n",
    "                  xcolumns=x.columns, \n",
    "                  model=modelo, points0=1000)\n",
    "card"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou entao usamos os resultados do woe_bin acima. Veja que usamos agora basepoints_eq0=False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'basepoints':      variable  bin  points\n",
       " 0  basepoints  NaN   788.0}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card2 = sc.scorecard(woe_bin, modelo, points0=1000,\n",
    "                    xcolumns=woe_bin.keys())\n",
    "card2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "o resultado da função \"scorecard\" por si não nos revela nada. Para converter os dados em score, temos que usar uma segunda função, a \"scorecard_ply\"...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. scorecard_ply\n",
    "Essa função calcular o score de credito usando os resultados da função \"scorecard\" e o banco de dados. Possui os seguintes parametros:\n",
    "1. dt: Banco de dados original\n",
    "2. card: output obtido da função 'scorecard'.\n",
    "3. only_total_score: default = TRUE, incluindo somente o score total. Se for False, o output inclui alem do score total, o score para cada variavel.\n",
    "4. print_step: Default = 1. Se print_step>0, mostra o nome das variáveis em cada iteração. Se print_step=0, nenhuma mensagem é mostrada.\n",
    "5. replace_blank_na: Substitui os valores em branco por NA. Default = True.\n",
    "6. var_kp: Determina o nome das colunas. Default = None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1 = sc.scorecard_ply(dataset, card2, only_total_score=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
